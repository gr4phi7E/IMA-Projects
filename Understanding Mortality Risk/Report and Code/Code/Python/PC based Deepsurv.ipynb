{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd5e6fcb-a588-4ae2-ae16-99b8998c7e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing split 1...\n",
      "Processing split 2...\n",
      "Processing split 3...\n",
      "Processing split 4...\n",
      "Processing split 5...\n",
      "Processing split 6...\n",
      "Processing split 7...\n",
      "Processing split 8...\n",
      "Processing split 9...\n",
      "Processing split 10...\n",
      "Processing split 11...\n",
      "Processing split 12...\n",
      "Processing split 13...\n",
      "Processing split 14...\n",
      "Processing split 15...\n",
      "Processing split 16...\n",
      "Processing split 17...\n",
      "Processing split 18...\n",
      "Processing split 19...\n",
      "Processing split 20...\n",
      "Processing split 21...\n",
      "Processing split 22...\n",
      "Processing split 23...\n",
      "Processing split 24...\n",
      "Processing split 25...\n",
      "Processing split 26...\n",
      "Processing split 27...\n",
      "Processing split 28...\n",
      "Processing split 29...\n",
      "Processing split 30...\n",
      "Processing split 31...\n",
      "Processing split 32...\n",
      "Processing split 33...\n",
      "Processing split 34...\n",
      "Processing split 35...\n",
      "Processing split 36...\n",
      "Processing split 37...\n",
      "Processing split 38...\n",
      "Processing split 39...\n",
      "Processing split 40...\n",
      "Processing split 41...\n",
      "Processing split 42...\n",
      "Processing split 43...\n",
      "Processing split 44...\n",
      "Processing split 45...\n",
      "Processing split 46...\n",
      "Processing split 47...\n",
      "Processing split 48...\n",
      "Processing split 49...\n",
      "Processing split 50...\n",
      "Processing split 51...\n",
      "Processing split 52...\n",
      "Processing split 53...\n",
      "Processing split 54...\n",
      "Processing split 55...\n",
      "Processing split 56...\n",
      "Processing split 57...\n",
      "Processing split 58...\n",
      "Processing split 59...\n",
      "Processing split 60...\n",
      "Processing split 61...\n",
      "Processing split 62...\n",
      "Processing split 63...\n",
      "Processing split 64...\n",
      "Processing split 65...\n",
      "Processing split 66...\n",
      "Processing split 67...\n",
      "Processing split 68...\n",
      "Processing split 69...\n",
      "Processing split 70...\n",
      "Processing split 71...\n",
      "Processing split 72...\n",
      "Processing split 73...\n",
      "Processing split 74...\n",
      "Processing split 75...\n",
      "Processing split 76...\n",
      "Processing split 77...\n",
      "Processing split 78...\n",
      "Processing split 79...\n",
      "Processing split 80...\n",
      "Processing split 81...\n",
      "Processing split 82...\n",
      "Processing split 83...\n",
      "Processing split 84...\n",
      "Processing split 85...\n",
      "Processing split 86...\n",
      "Processing split 87...\n",
      "Processing split 88...\n",
      "Processing split 89...\n",
      "Processing split 90...\n",
      "Processing split 91...\n",
      "Processing split 92...\n",
      "Processing split 93...\n",
      "Processing split 94...\n",
      "Processing split 95...\n",
      "Processing split 96...\n",
      "Processing split 97...\n",
      "Processing split 98...\n",
      "Processing split 99...\n",
      "Processing split 100...\n",
      "All splits processed. Results saved to c_index_results.csv.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import torch\n",
    "import torchtuples as tt\n",
    "from pycox.models import CoxPH\n",
    "from pycox.evaluation import EvalSurv\n",
    "import os\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Fixed columns\n",
    "cols_standardize = ['Age','BMI', 'poverty_level', 'PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9']\n",
    "cols_leave = ['Race', 'sex', 'Mobility', 'diabetes.y', 'Asthma', 'Arthritis', 'heart_failure', 'coronary_heart_disease', \n",
    "              'angina', 'stroke', 'thyroid', 'bronchitis', 'cancer']\n",
    "\n",
    "standardize = [([col], StandardScaler()) for col in cols_standardize]\n",
    "leave = [(col, None) for col in cols_leave]\n",
    "x_mapper = DataFrameMapper(standardize + leave)\n",
    "\n",
    "# Model architecture\n",
    "def get_model(input_dim):\n",
    "    num_nodes = [256, 256]\n",
    "    net = tt.practical.MLPVanilla(input_dim, num_nodes, 1, batch_norm=True, dropout=0.7, output_bias=False).to(device)\n",
    "    return CoxPH(net, tt.optim.Adam)\n",
    "\n",
    "# For C-index storage\n",
    "c_index_list = []\n",
    "\n",
    "# Directory containing the splits\n",
    "split_dir = \"D:/Final_Year_Project/splits_final/\"  # Modify this if needed\n",
    "\n",
    "for i in range(1, 101):\n",
    "    print(f\"Processing split {i}...\")\n",
    "\n",
    "    # Load train/test split\n",
    "    df_train = pd.read_csv(os.path.join(split_dir, f\"train_split_{i}.csv\"))\n",
    "    df_test = pd.read_csv(os.path.join(split_dir, f\"test_split_{i}.csv\"))\n",
    "\n",
    "    # Fit transformer only on training data\n",
    "    x_train = torch.tensor(x_mapper.fit_transform(df_train).astype('float32')).to(device)\n",
    "    x_val = torch.tensor(x_mapper.transform(df_test).astype('float32')).to(device)\n",
    "    x_test = torch.tensor(x_mapper.transform(df_test).astype('float32')).to(device)\n",
    "\n",
    "    # Get target\n",
    "    get_target = lambda df: (\n",
    "        torch.tensor(df['time_mort'].values, dtype=torch.float32).to(device),\n",
    "        torch.tensor(df['mortstat'].values, dtype=torch.float32).to(device)\n",
    "    )\n",
    "    y_train = get_target(df_train)\n",
    "    y_val = get_target(df_test)\n",
    "    durations_test, events_test = get_target(df_test)\n",
    "    val = x_val, y_val\n",
    "\n",
    "    durations_np = durations_test.cpu().numpy()\n",
    "    events_np = events_test.cpu().numpy()\n",
    "\n",
    "    # Model\n",
    "    model = get_model(x_train.shape[1])\n",
    "\n",
    "    # Find LR\n",
    "    batch_size = 64\n",
    "    lrfinder = model.lr_finder(x_train, y_train, batch_size, tolerance=10)\n",
    "    best_lr = lrfinder.get_best_lr()\n",
    "    model.optimizer.set_lr(best_lr)\n",
    "\n",
    "    # Train\n",
    "    callbacks = [tt.callbacks.EarlyStopping()]\n",
    "    model.fit(x_train, y_train, batch_size, 512, callbacks, verbose=False, \n",
    "              val_data=val, val_batch_size=batch_size)\n",
    "\n",
    "    # Predict survival\n",
    "    model.compute_baseline_hazards()\n",
    "    surv = model.predict_surv_df(x_test)\n",
    "    ev = EvalSurv(surv, durations_np, events_np, censor_surv='km')\n",
    "    c_index = ev.concordance_td()\n",
    "    c_index_list.append(c_index)\n",
    "\n",
    "# Save C-indices\n",
    "c_index_df = pd.DataFrame({'split': list(range(1, 101)), 'c_index': c_index_list})\n",
    "# c_index_df.to_csv(\"D:/Final_Year_Project/c_index_results.csv\", index=False)\n",
    "\n",
    "print(\"All splits processed. Results saved to c_index_results.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2061de75-3a42-4e5d-98ae-167873a74f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7817317342027168"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(c_index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27673895-1b00-4abe-a3bb-f1d5107726c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_index_df.to_csv(\"D:/Final_Year_Project/c_index_PCdeepsurv.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
